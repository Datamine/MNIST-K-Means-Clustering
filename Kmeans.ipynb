{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# John Loeber | contact@johnloeber.com\n",
      "import random\n",
      "from base64 import b64decode\n",
      "from json import loads\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "# set matplotlib to display all plots inline with the notebook\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse(x):\n",
      "    \"\"\"\n",
      "    to parse the digits file into tuples of \n",
      "    (labelled digit, numpy array of vector representation of digit)\n",
      "    \"\"\"\n",
      "    digit = loads(x)\n",
      "    array = np.fromstring(b64decode(digit[\"data\"]),dtype=np.ubyte)\n",
      "    return (digit[\"label\"], array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in the digits file. Digits is a list of 60,000 tuples,\n",
      "# each representing a labelled digit and its vector representation.\n",
      "with open(\"digits.base64.json\",\"r\") as f:\n",
      "    digits = map(parse, f.readlines())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pick a ratio for splitting the digits list into a training and a validation set.\n",
      "ratio = int(len(digits)*0.25)\n",
      "validation = digits[:ratio]\n",
      "training = digits[ratio:]\n",
      "# create corresponding training and validation sets without labels\n",
      "no_label_validation = map(lambda x: x[1], validation)\n",
      "no_label_training = map(lambda x: x[1], training)\n",
      "\n",
      "small_test = no_label_training[:5000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display_digits(digits, labeled=True, scale=True):\n",
      "    for i in xrange(len(digits)):\n",
      "        if labeled:\n",
      "            digit = digits[i][1]\n",
      "        else:\n",
      "            digit = digits[i]\n",
      "        image = digit\n",
      "        #if scale:\n",
      "        #    print image\n",
      "        #    image = image.astype(float) * (1.0 / 256)\n",
      "        plt.figure(i)\n",
      "        fig = plt.imshow(image.reshape(28, 28))\n",
      "        fig.set_cmap('gray_r')\n",
      "        fig.axes.get_xaxis().set_visible(False)\n",
      "        fig.axes.get_yaxis().set_visible(False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 276
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# writing Lloyd's Algorithm for K-Means clustering.\n",
      "# (This exists in various libraries, but it's good practice to write by hand.)\n",
      "def init_centroids(data,k):\n",
      "    \"\"\"\n",
      "    randomly pick some k centers from the data as starting values for centroids.\n",
      "    \"\"\"\n",
      "    return random.sample(data,k)\n",
      "\n",
      "def sum_arrays(arraylist):\n",
      "    \"\"\"\n",
      "    from http://stackoverflow.com/questions/20640396/quickly-summing-numpy-arrays-element-wise\n",
      "    element-wise sums a list of ndarrays\n",
      "    \"\"\"\n",
      "    # assumes len(arraylist) > 0\n",
      "    sum_ = arraylist[0].copy()\n",
      "    for a in arraylist[1:]:\n",
      "        sum_ += a\n",
      "    return sum_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def form_clusters(data,centroids):\n",
      "    \"\"\"\n",
      "    given some data and centroids for the data, allocate each datapoint\n",
      "    to its closest centroids. This forms clusters.\n",
      "    \"\"\"\n",
      "    # initialize an empty list for each centroid. The list will contain\n",
      "    # all the datapoints that are closer to that centroid than to any other.\n",
      "    # That list is the cluster of that centroid.\n",
      "    \n",
      "    # enumerate because centroids are ndarrays which are unhashable,\n",
      "    # so a dictionary can't index with them\n",
      "    centroids_indices = range(len(centroids))\n",
      "    clusters = {c: [] for c in centroids_indices}\n",
      "    \n",
      "    for Xi in data:\n",
      "        # for each datapoint, pick the closest centroid.\n",
      "        closest_centroid_index = None\n",
      "        smallest_distance = float(\"inf\")\n",
      "        for cj_index in centroids_indices:\n",
      "            cj = centroids[cj_index]\n",
      "            distance = np.linalg.norm(Xi - cj)\n",
      "            if distance < smallest_distance:\n",
      "                closest_centroid_index = cj_index\n",
      "                smallest_distance = distance\n",
      "        # allocate that datapoint to the cluster of that centroid.\n",
      "        clusters[closest_centroid_index].append(Xi)\n",
      "    return clusters.values()\n",
      "\n",
      "def mean_cluster(cluster):\n",
      "    \"\"\"\n",
      "    computes the mean of a list of vectors (a cluster).\n",
      "    take the sum and then divide by the size of the cluster to get the\n",
      "    mean -- i.e. to get the centroid at the middle of the cluster.\n",
      "    NOTE: taking the mean risks influence by outliers. Taking the median\n",
      "    is occasionally better, and that's known as K-median clustering.   \n",
      "    \"\"\"\n",
      "    sum_of_points = sum_arrays(cluster)\n",
      "    mean_of_points = sum_of_points * (1.0 / len(cluster))\n",
      "    return mean_of_points\n",
      "\n",
      "def move_centroids(clusters):\n",
      "    \"\"\"\n",
      "    'clusters' is (dictionary of {centroid: list of datapoints in its cluster}).\n",
      "    For each item in clusters, move the centroid into the middle of the cluster.\n",
      "    \"\"\"\n",
      "    new_centroids = []\n",
      "    for cluster in clusters:\n",
      "        new_centroids.append(mean_cluster(cluster))\n",
      "    return new_centroids\n",
      "\n",
      "def repeat_until_convergence(data,clusters, centroids):\n",
      "    \"\"\"\n",
      "    form clusters around centroids, then keep moving the centroids\n",
      "    until the moves are no longer significant, i.e. we've found\n",
      "    the best-fitting centroids for the data.\n",
      "    \"\"\"\n",
      "    previous_max_difference = 0\n",
      "    #keep_iterating = True\n",
      "    count = 0\n",
      "    while count <5:\n",
      "        count +=1\n",
      "        old_centroids = centroids\n",
      "        print [len(x) for x in clusters]\n",
      "        #display_digits(old_centroids,labeled=False)\n",
      "        centroids = move_centroids(clusters)\n",
      "        clusters = form_clusters(data,centroids)\n",
      "        print [len(x) for x in clusters]\n",
      "        # we keep old_clusters and clusters so we can get the maximum difference\n",
      "        # between centroid positions every time. we say the centroids have converged\n",
      "        # when the maximum difference between centroid positions changes by less than\n",
      "        # 1% during iterations. Note: that is a threshold that I set arbitrarily.    \n",
      "        \"\"\"\n",
      "        differences = map(lambda a, b: np.linalg.norm(a-b),old_centroids,new_centroids)\n",
      "        max_difference = max(differences)\n",
      "        difference_change = abs((max_difference-previous_max_difference)/np.mean([previous_max_difference,max_difference])) * 100\n",
      "        previous_max_difference = max_difference\n",
      "        print difference_change\n",
      "        if difference_change < 0.1:\n",
      "            break\n",
      "        \"\"\"\n",
      "    return clusters, new_centroids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 299
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centroids = init_centroids(small_test, 10)\n",
      "clusters = form_clusters(small_test, centroids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_clusters, final_centroids = repeat_until_convergence(small_test, clusters, centroids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[484, 534, 508, 498, 510, 511, 521, 482, 519, 433]\n",
        "[76, 0, 1, 6, 46, 0, 1, 3, 1, 4866]"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-301-c5d8d1feb039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_until_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-299-22f549416a3a>\u001b[0m in \u001b[0;36mrepeat_until_convergence\u001b[0;34m(data, clusters, centroids)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#display_digits(old_centroids,labeled=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-299-22f549416a3a>\u001b[0m in \u001b[0;36mmove_centroids\u001b[0;34m(clusters)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mnew_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mnew_centroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_centroids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-299-22f549416a3a>\u001b[0m in \u001b[0;36mmean_cluster\u001b[0;34m(cluster)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mis\u001b[0m \u001b[0moccasionally\u001b[0m \u001b[0mbetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mknown\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmedian\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0msum_of_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mmean_of_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_of_points\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean_of_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-265-8d1024ffcc8f>\u001b[0m in \u001b[0;36msum_arrays\u001b[0;34m(arraylist)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# assumes len(arraylist) > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0msum_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marraylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marraylist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msum_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[76, 0, 1, 6, 46, 0, 1, 3, 1, 4866]\n"
       ]
      }
     ],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array([int(random.uniform(0,255)) for x in range(10)]) * 1.28"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 207,
       "text": [
        "array([ 299.52,   19.2 ,  275.2 ,   89.6 ,   11.52,  125.44,   66.56,\n",
        "        131.84,   25.6 ,   11.52])"
       ]
      }
     ],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "clusters = KMeans.train(nolabelTraining, 10, maxIterations=50, runs=10, initializationMode=\"random\")\n",
      "\n",
      "\n",
      "\n",
      "# Part A\n",
      "centers = clusters.centers\n",
      "\n",
      "# this explicit form is pretty ugly but it works -- a list comprehension raised some issues w/r/t/ shallow copy.\n",
      "zeros = training.filter(lambda x : x[0] == 0)\n",
      "ones = training.filter(lambda x : x[0] == 1)\n",
      "twos = training.filter(lambda x : x[0] == 2)\n",
      "threes = training.filter(lambda x : x[0] == 3)\n",
      "fours = training.filter(lambda x : x[0] == 4)\n",
      "fives = training.filter(lambda x : x[0] == 5)\n",
      "sixes = training.filter(lambda x : x[0] == 6)\n",
      "sevens = training.filter(lambda x : x[0] == 7)\n",
      "eights = training.filter(lambda x : x[0] == 8)\n",
      "nines = training.filter(lambda x : x[0] == 9)\n",
      "\n",
      "# the 'labels' are the best-fitting centers for each digit\n",
      "labelsAndCenters = {}\n",
      "for number in [zeros,ones,twos,threes,fours,fives,sixes,sevens,eights,nines]:\n",
      "    # initialize some arbitrarily large minimum distance\n",
      "    mindist = 100000000000000\n",
      "    minc = 0\n",
      "    for c in clusters.centers:\n",
      "        sumdist = number.map(lambda xi : numpy.linalg.norm(xi[1] - c)**2).sum()\n",
      "        if sumdist < mindist:\n",
      "            mindist = sumdist\n",
      "            minc = c\n",
      "    labelsAndCenters[number.first()[0]] = minc\n",
      "    \n",
      "    # Solution to (A), commented out to save space\n",
      "\n",
      "#print labelsAndCenters\n",
      "\n",
      "# Part B\n",
      "\n",
      "# The question here was somewhat unclear -- someone asked about this on Piazza, but got no answer.\n",
      "# I'm assuming that what you want me to do is to display the images of the ten centroids for the digits,\n",
      "# and their corresponding labels. (Another possibility was that you want me to reduce the dimension of the vectors\n",
      "# and plot the centroids and data on a 2d grid.)\n",
      "\n",
      "def inlineDisplay(LC):\n",
      "    for i in LC:\n",
      "        image = LC[i]\n",
      "        image = image.astype(float)/256\n",
      "        plt.figure(i)\n",
      "        fig = plt.imshow(image.reshape(28,28))\n",
      "        fig.set_cmap('gray_r')\n",
      "        fig.axes.get_xaxis().set_visible(False)\n",
      "        fig.axes.get_yaxis().set_visible(False)\n",
      "        plt.title(\"Digit \" + str(i))\n",
      "\n",
      "        \n",
      "        inlineDisplay(labelsAndCenters)\n",
      "        \n",
      "# Note that the digits 4 and 9 are assigned the same centroid. This makes sense -- they are visually very similar. \n",
      "# I thought about making a condition such that each centroid could only be assigned to one label, but this wouldn't be a \n",
      "# real solution -- all it would do is arbitrarily prioritize one centroid over another. \n",
      "\n",
      "# Part C.\n",
      "\n",
      "# Strategy: take the development set. For every digit in the development set, try to classify it \n",
      "# using labelsAndCenters, the dictionary of { Label : Centroid }, e.g. { 0 : <NP Array of the Centroid of Digit 0>}\n",
      "# by finding the Centroid with the minimum distance to that digit. \n",
      "\n",
      "def classify(digit):\n",
      "    # find the best label\n",
      "    mindistance = 100000000000\n",
      "    bestlabel = None\n",
      "    for k in labelsAndCenters:\n",
      "        distance = numpy.linalg.norm(digit[1] - labelsAndCenters[k])**2\n",
      "        if distance < mindistance:\n",
      "            mindistance = distance\n",
      "            bestlabel = k\n",
      "    # compare best label to actual label. return 1 if classified correctly.\n",
      "    if bestlabel == digit[0]:\n",
      "        return 1\n",
      "    else:\n",
      "        return 0\n",
      "\n",
      "# Wait: the following is actually not our solution to Part (C). Read on...\n",
      "    \n",
      "correct = development.map(classify).sum()\n",
      "incorrect = development.count() - correct\n",
      "\n",
      "print \"Number of Digits in Development Set: \", str(development.count())\n",
      "print \"Correct Classifications: \", str(correct)\n",
      "print \"Incorrect Classifications (Error): \", str(incorrect)\n",
      "print \"Error Rate (Incorrect Classifications / Total Classifications: \", str(float(correct)/development.count())\n",
      "\n",
      "# Part D\n",
      "\n",
      "# Refactoring some of the code from previous parts:\n",
      "    \n",
      "# note that this version of `getlabelsandclusters` is different from the one from part (A) in that it\n",
      "# tries to assign fitting labels to clusters, not clusters to labels.\n",
      "\n",
      "def getlabelsandcenters(ccc):\n",
      "    # (cluster,digit) tuples\n",
      "    output = []\n",
      "    for c in ccc:\n",
      "        # initialize some arbitrarily large minimum distance\n",
      "        mindist = 100000000000\n",
      "        minNum = 0\n",
      "        for number in [zeros,ones,twos,threes,fours,fives,sixes,sevens,eights,nines]:\n",
      "            sumdist = number.map(lambda xi: numpy.linalg.norm(xi[1]-c)**2).sum()\n",
      "            if sumdist < mindist:\n",
      "                mindist = sumdist\n",
      "                minNum = number.first()[0]\n",
      "        # have to use tuples rather than a dict b/c numpy ndarrays and lists are unhashable types\n",
      "        output.append((c,minNum))\n",
      "    return output\n",
      "\n",
      "def tupclassify(digit):\n",
      "    # find the best label\n",
      "    mindistance = 100000000000\n",
      "    bestlabel = None\n",
      "    for (img,label) in labelsAndCenters:\n",
      "        distance = numpy.linalg.norm(digit[1] - img)**2\n",
      "        if distance < mindistance:\n",
      "            mindistance = distance\n",
      "            bestlabel = digit[0]\n",
      "    # compare best label to actual label. return 1 if classified correctly.\n",
      "    if bestlabel == label:\n",
      "        return 1\n",
      "    else:\n",
      "        return 0\n",
      "    \n",
      "    labelsAndCenters = getlabelsandcenters(clusters.centers)\n",
      "\n",
      "# Given this updated method of getting the labels and clusters, below is the *real* solution to Part C.\n",
      "# The error rate of 0.1 is much better. It is surprising for this to be such a stronger fit. \n",
      "# (I would have thought that fitting labels to clusters is symmetrical with fitting clusters to labels.)\n",
      "\n",
      "correct = development.map(tupclassify).sum()\n",
      "incorrect = development.count() - correct\n",
      "\n",
      "print \"Number of Digits in Development Set: \", str(development.count())\n",
      "print \"Correct Classifications: \", str(correct)\n",
      "print \"Incorrect Classifications (Error): \", str(incorrect)\n",
      "print \"Error Rate (Incorrect Classifications / Total Classifications: \", str(float(correct)/development.count())\n",
      "\n",
      "ErrorRates = {10:0.1032}\n",
      "\n",
      "# Now computing error rates for larger cluster numbers. Keeping MaxIterations and Runs constant.\n",
      "# Getting the clusters and computing the labelsAndCenters takes a while, so we do this manually.\n",
      "\n",
      "clusters2 = KMeans.train(nolabelTraining, 12, maxIterations=50, runs=10, initializationMode=\"random\")\n",
      "\n",
      "labelsAndCenters = getlabelsandcenters(clusters2.centers)\n",
      "correct = development.map(tupclassify).sum()\n",
      "ErrorRates[12] = float(correct)/development.count()\n",
      "\n",
      "clusters3 = KMeans.train(nolabelTraining, 15, maxIterations=50, runs=10, initializationMode=\"random\")\n",
      "# I know I should wrap the 3 lines of code below in a helper function because I use them often\n",
      "# But this creates scoping problems and I'm working too close to the deadline to be able to afford fixing that\n",
      "labelsAndCenters = getlabelsandcenters(clusters3.centers)\n",
      "correct = development.map(tupclassify).sum()\n",
      "ErrorRates[15] = float(correct)/development.count()\n",
      "\n",
      "# I didn't have enough time to plot results for many clusters! It appears that 12 clusters is optimal.\n",
      "\n",
      "ErrorRateListX = ErrorRates.keys()\n",
      "ErrorRateListY = [ErrorRates[k] for k in ErrorRateListX]\n",
      "plt.figure(\"Final\")\n",
      "plt.title(\"Error Rates and Clusters\")\n",
      "plt.scatter(ErrorRateListX,ErrorRateListY)\n",
      "plt.plot(ErrorRateListX,ErrorRateListY)\n",
      "plt.xlabel('Number of Clusters')\n",
      "plt.ylabel('Error Rate')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}